{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:No module named 'tempeh': fetch_lawschool_gpa will be unavailable. To install, run:\n",
      "pip install 'aif360[LawSchoolGPA]'\n"
     ]
    }
   ],
   "source": [
    "from aif360.sklearn.datasets import fetch_german\n",
    "\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, MinMaxScaler\n",
    "from sklearn.metrics import fbeta_score, make_scorer, accuracy_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "def load_dataset():\n",
    "    # load the dataset as a numpy array\n",
    "    dataset = fetch_german()\n",
    "    # split into inputs and outputs\n",
    "    X, y = dataset.X, dataset.y\n",
    "\n",
    "    # transform the age column into zero and one depending on the age being greater than 25\n",
    "    X['age'] = X['age'].apply(lambda x: 0 if x <= 25 else 1)\n",
    "\n",
    "    # transform the sex column into 0 or 1\n",
    "    X['sex'] = X['sex'].apply(lambda x: 0 if x == 'female' else 1).astype(int)\n",
    "\n",
    "    # select categorical features\n",
    "    cat_ix = X.select_dtypes(include=['category']).columns\n",
    "    num_ix = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "    # one hot encode cat features only\n",
    "    # label encode the target variable to have the classes 0 and 1\n",
    "    y = LabelEncoder().fit_transform(y)\n",
    "    return X, y, cat_ix, num_ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dhasade/anaconda3/envs/audits/lib/python3.8/site-packages/sklearn/datasets/_openml.py:1002: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "X, y, cat_ix, num_ix = load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(age = 1): 0.81\n",
      "P(age = 0): 0.18999999999999995\n",
      "P(sex = 1): 0.69\n",
      "P(sex = 0): 0.31000000000000005\n"
     ]
    }
   ],
   "source": [
    "# Calculate the probabilities\n",
    "prob_age_1 = X['age'].mean()  # P(age = 1)\n",
    "prob_age_0 = 1 - prob_age_1   # P(age = 0)\n",
    "\n",
    "prob_sex_1 = X['sex'].mean()  # P(sex = 1)\n",
    "prob_sex_0 = 1 - prob_sex_1   # P(sex = 0)\n",
    "\n",
    "print(\"P(age = 1):\", prob_age_1)\n",
    "print(\"P(age = 0):\", prob_age_0)\n",
    "print(\"P(sex = 1):\", prob_sex_1)\n",
    "print(\"P(sex = 0):\", prob_sex_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(y=1|age=0): 0.5789473684210527\n",
      "P(y=1|age=1): 0.7283950617283951\n",
      "P(y=1|sex=0): 0.6483870967741936\n",
      "P(y=1|sex=1): 0.7231884057971014\n"
     ]
    }
   ],
   "source": [
    "# Calculate the conditional probabilities\n",
    "prob_y_given_age_0 = y[X['age'] == 0].mean()  # P(y=1|age=0)\n",
    "prob_y_given_age_1 = y[X['age'] == 1].mean()  # P(y=1|age=1)\n",
    "\n",
    "prob_y_given_sex_0 = y[X['sex'] == 0].mean()  # P(y=1|sex=0)\n",
    "prob_y_given_sex_1 = y[X['sex'] == 1].mean()  # P(y=1|sex=1)\n",
    "\n",
    "print(\"P(y=1|age=0):\", prob_y_given_age_0)\n",
    "print(\"P(y=1|age=1):\", prob_y_given_age_1)\n",
    "print(\"P(y=1|sex=0):\", prob_y_given_sex_0)\n",
    "print(\"P(y=1|sex=1):\", prob_y_given_sex_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(y=1|sex=1, age=1): 0.7388429752066116\n",
      "P(y=1|sex=1, age=0): 0.611764705882353\n",
      "P(y=1|sex=0, age=1): 0.697560975609756\n",
      "P(y=1|sex=0, age=0): 0.5523809523809524\n"
     ]
    }
   ],
   "source": [
    "# Calculate the joint probabilities\n",
    "prob_y_given_sex_1_and_age_1 = y[(X['sex'] == 1) & (X['age'] == 1)].mean()  # P(y=1|sex=1, age=1)\n",
    "prob_y_given_sex_1_and_age_0 = y[(X['sex'] == 1) & (X['age'] == 0)].mean()  # P(y=1|sex=1, age=0)\n",
    "prob_y_given_sex_0_and_age_1 = y[(X['sex'] == 0) & (X['age'] == 1)].mean()  # P(y=1|sex=0, age=1)\n",
    "prob_y_given_sex_0_and_age_0 = y[(X['sex'] == 0) & (X['age'] == 0)].mean()  # P(y=1|sex=0, age=0)\n",
    "\n",
    "print(\"P(y=1|sex=1, age=1):\", prob_y_given_sex_1_and_age_1)\n",
    "print(\"P(y=1|sex=1, age=0):\", prob_y_given_sex_1_and_age_0)\n",
    "print(\"P(y=1|sex=0, age=1):\", prob_y_given_sex_0_and_age_1)\n",
    "print(\"P(y=1|sex=0, age=0):\", prob_y_given_sex_0_and_age_0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def demographic_parity(samples, y, attribute):\n",
    "    # Calculate demographic parity for 'attribute'\n",
    "    prob_y_given_attribute_1 = y[samples[attribute] == 1].mean()  # P(y=1|attribute=1)\n",
    "    prob_y_given_attribute_0 = y[samples[attribute] == 0].mean()  # P(y=1|attribute=0)\n",
    "\n",
    "    demographic_parity_attribute = abs(prob_y_given_attribute_1 - prob_y_given_attribute_0)\n",
    "\n",
    "    return demographic_parity_attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Demographic Parity for 'sex': 0.07480130902290782\n",
      "Demographic Parity for 'age': 0.14944769330734242\n"
     ]
    }
   ],
   "source": [
    "# Demographic parity in the original dataset\n",
    "demographic_parity_age = demographic_parity(X, y, 'age')\n",
    "demographic_parity_sex = demographic_parity(X, y, 'sex')\n",
    "\n",
    "print(\"Demographic Parity for 'sex':\", demographic_parity_sex)\n",
    "print(\"Demographic Parity for 'age':\", demographic_parity_age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split X and y into train, test and audit splits of 45%, 5% and 50% respectively\n",
    "random_seed = 40\n",
    "X_train, X_audit, y_train, y_audit = train_test_split(X, y, test_size=0.5, random_state=random_seed)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.1, random_state=random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define models to test\n",
    "def get_models():\n",
    "    models, names = list(), list()\n",
    "    # LR\n",
    "    models.append(LogisticRegression(solver='liblinear'))\n",
    "    names.append('LR')\n",
    "    # LDA\n",
    "    models.append(LinearDiscriminantAnalysis())\n",
    "    names.append('LDA')\n",
    "    # NB\n",
    "    models.append(GaussianNB())\n",
    "    names.append('NB')\n",
    "    # GPC\n",
    "    models.append(GaussianProcessClassifier())\n",
    "    names.append('GPC')\n",
    "    # SVM\n",
    "    models.append(SVC(gamma='scale'))\n",
    "    names.append('SVM')\n",
    "    return models, names\n",
    "\n",
    "models, names = get_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the preprocessing\n",
    "ct = ColumnTransformer([('c',OneHotEncoder(),cat_ix), ('n',MinMaxScaler(),num_ix)])\n",
    "X_train = ct.fit_transform(X_train)\n",
    "X_test = ct.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Accuracy: 0.82\n",
      "LDA Accuracy: 0.78\n",
      "NB Accuracy: 0.5\n",
      "GPC Accuracy: 0.72\n",
      "SVM Accuracy: 0.78\n",
      "Best model: LR with accuracy: 0.82\n"
     ]
    }
   ],
   "source": [
    "models, names = get_models()\n",
    "best_acc = 0.0; best_model = None; best_model_name = None\n",
    "for i in range(len(models)):\n",
    "\n",
    "    model = models[i]\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # evaluate the model\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"{names[i]} Accuracy: {accuracy}\")\n",
    "\n",
    "    if accuracy > best_acc:\n",
    "        best_acc = accuracy\n",
    "        best_model = model\n",
    "        best_model_name = names[i]\n",
    "\n",
    "print(f\"Best model: {best_model_name} with accuracy: {best_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Demographic Parity for 'age': 0.22612085769980506\n",
      "Demographic Parity for 'sex': 0.15521271622253385\n"
     ]
    }
   ],
   "source": [
    "# Calculate the ground truth demographic parity of the best model\n",
    "# This should be done on all data (train + test+ audit)\n",
    "X_temp = ct.transform(X)\n",
    "y_pred = best_model.predict(X_temp)\n",
    "\n",
    "# Calculate demographic parity for 'age'\n",
    "prob_y_given_age_1 = y_pred[X['age'] == 1].mean()  # P(y=1|age=1)\n",
    "prob_y_given_age_0 = y_pred[X['age'] == 0].mean()  # P(y=1|age=0)\n",
    "\n",
    "demographic_parity_age_of_model = abs(prob_y_given_age_1 - prob_y_given_age_0)\n",
    "print(\"Demographic Parity for 'age':\", demographic_parity_age_of_model)\n",
    "\n",
    "# Calculate demographic parity for 'sex'\n",
    "prob_y_given_sex_1 = y_pred[X['sex'] == 1].mean()  # P(y=1|sex=1)\n",
    "prob_y_given_sex_0 = y_pred[X['sex'] == 0].mean()  # P(y=1|sex=0)\n",
    "\n",
    "demographic_parity_sex_of_model = abs(prob_y_given_sex_1 - prob_y_given_sex_0)\n",
    "print(\"Demographic Parity for 'sex':\", demographic_parity_sex_of_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_DP(samples, y, attribute, groud_truth_dp):\n",
    "    # Calculate the error in demographic parity for 'attribute'\n",
    "    return np.abs(groud_truth_dp - demographic_parity(samples, y, attribute))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct_new = ColumnTransformer([('c',OneHotEncoder(),cat_ix), ('n',MinMaxScaler(),num_ix)])\n",
    "ct_new.fit_transform(X_audit)\n",
    "\n",
    "def BlackBox(samples):\n",
    "    '''\n",
    "    The black-box algorithm to audit\n",
    "    samples : pandas.DataFrame\n",
    "        The dataset.\n",
    "    '''\n",
    "    # transform using the same ColumnTransformer object used for the training data\n",
    "    transformed_samples = ct_new.transform(samples)\n",
    "    # predict\n",
    "    yhat = best_model.predict(transformed_samples)\n",
    "\n",
    "    # return yhat along with samples\n",
    "    return samples, yhat\n",
    "\n",
    "def RS(samples, n, attribute):\n",
    "    '''\n",
    "    Random Sampling.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    samples : pandas.DataFrame\n",
    "        The dataset.\n",
    "    n : int\n",
    "        The number of samples to be generated.\n",
    "    attribute : str\n",
    "        The attribute to be sampled.\n",
    "\n",
    "    Attribute is not used in the method.\n",
    "    '''\n",
    "\n",
    "    subset = samples.sample(n=n, random_state=42)\n",
    "    \n",
    "    return BlackBox(subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in demographic parity for 'age': 0.35324422166527425\n",
      "Error in demographic parity for 'sex': 0.1434885824787649\n"
     ]
    }
   ],
   "source": [
    "samples, yhat = RS(X_audit, 25, 'age')\n",
    "\n",
    "# calculate the error in demographic parity for 'age'\n",
    "error_age = error_DP(samples, yhat, 'age')\n",
    "print(\"Error in demographic parity for 'age':\", error_age)\n",
    "\n",
    "samples, yhat = RS(X_audit, 25, 'sex')\n",
    "\n",
    "# calculate the error in demographic parity for 'sex'\n",
    "error_sex = error_DP(samples, yhat, 'sex')\n",
    "print(\"Error in demographic parity for 'sex':\", error_sex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "audits",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
