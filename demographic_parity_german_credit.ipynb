{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from aif360.sklearn.datasets import fetch_german\n",
    "\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder, MinMaxScaler\n",
    "from sklearn.metrics import fbeta_score, make_scorer, accuracy_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from matplotlib import pyplot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the dataset\n",
    "def load_dataset():\n",
    "    # load the dataset as a numpy array\n",
    "    dataset = fetch_german()\n",
    "    # split into inputs and outputs\n",
    "    X, y = dataset.X, dataset.y\n",
    "\n",
    "    # transform the age column into zero and one depending on the age being greater than 25\n",
    "    X['age'] = X['age'].apply(lambda x: 0 if x <= 25 else 1)\n",
    "\n",
    "    # transform the sex column into 0 or 1\n",
    "    X['sex'] = X['sex'].apply(lambda x: 0 if x == 'female' else 1).astype(int)\n",
    "\n",
    "    # transform the marital_status column into 0 or 1\n",
    "    X['marital_status'] = X['marital_status'].apply(lambda x: 0 if x == 'single' else 1).astype(int)\n",
    "\n",
    "    # transform the own_telephone column into 0 or 1\n",
    "    X['own_telephone'] = X['own_telephone'].apply(lambda x: 0 if x == 'none' else 1).astype(int)\n",
    "\n",
    "    # transform the employment column into 0 or 1\n",
    "    X['employment'] = X['employment'].apply(lambda x: 1 if x == '4<=X<7' or x == '>=7' else 0).astype(int)    \n",
    "    \n",
    "    # select categorical features\n",
    "    cat_ix = X.select_dtypes(include=['category']).columns\n",
    "    num_ix = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "    # one hot encode cat features only\n",
    "    # label encode the target variable to have the classes 0 and 1\n",
    "    y = LabelEncoder().fit_transform(y)\n",
    "    return X, y, cat_ix, num_ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dhasade/.local/lib/python3.8/site-packages/sklearn/datasets/_openml.py:1022: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "X, y, cat_ix, num_ix = load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'numpy.ndarray' object has no attribute 'info'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/dhasade/audits/ml-audits/demographic_parity_german_credit.ipynb Cell 4\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Blabosgodzilla.iccluster.epfl.ch/home/dhasade/audits/ml-audits/demographic_parity_german_credit.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m y\u001b[39m.\u001b[39;49minfo()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'numpy.ndarray' object has no attribute 'info'"
     ]
    }
   ],
   "source": [
    "y.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.DataFrame(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0\n",
       "0    1\n",
       "1    0\n",
       "2    1\n",
       "3    1\n",
       "4    0\n",
       "..  ..\n",
       "995  1\n",
       "996  1\n",
       "997  1\n",
       "998  0\n",
       "999  1\n",
       "\n",
       "[1000 rows x 1 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "MultiIndex: 1000 entries, ('male', 'aged', 'yes') to ('male', 'aged', 'yes')\n",
      "Data columns (total 21 columns):\n",
      " #   Column                  Non-Null Count  Dtype   \n",
      "---  ------                  --------------  -----   \n",
      " 0   checking_status         1000 non-null   category\n",
      " 1   duration                1000 non-null   float64 \n",
      " 2   credit_history          1000 non-null   category\n",
      " 3   purpose                 1000 non-null   category\n",
      " 4   credit_amount           1000 non-null   float64 \n",
      " 5   savings_status          1000 non-null   category\n",
      " 6   employment              1000 non-null   int64   \n",
      " 7   installment_commitment  1000 non-null   float64 \n",
      " 8   other_parties           1000 non-null   category\n",
      " 9   residence_since         1000 non-null   float64 \n",
      " 10  property_magnitude      1000 non-null   category\n",
      " 11  age                     1000 non-null   int64   \n",
      " 12  other_payment_plans     1000 non-null   category\n",
      " 13  housing                 1000 non-null   category\n",
      " 14  existing_credits        1000 non-null   float64 \n",
      " 15  job                     1000 non-null   category\n",
      " 16  num_dependents          1000 non-null   float64 \n",
      " 17  own_telephone           1000 non-null   int64   \n",
      " 18  foreign_worker          1000 non-null   category\n",
      " 19  sex                     1000 non-null   int64   \n",
      " 20  marital_status          1000 non-null   int64   \n",
      "dtypes: category(10), float64(6), int64(5)\n",
      "memory usage: 99.5 KB\n"
     ]
    }
   ],
   "source": [
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "marital_status\n",
       "single         548\n",
       "div/dep/mar    310\n",
       "mar/wid         92\n",
       "div/sep         50\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X['marital_status'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "employment\n",
       "1<=X<4        339\n",
       ">=7           253\n",
       "4<=X<7        174\n",
       "<1            172\n",
       "unemployed     62\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X['employment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "employment\n",
       "0    573\n",
       "1    427\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X['employment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "own_telephone\n",
       "0    596\n",
       "1    404\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X['own_telephone'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = X[X['age'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:No module named 'tempeh': fetch_lawschool_gpa will be unavailable. To install, run:\n",
      "pip install 'aif360[LawSchoolGPA]'\n"
     ]
    }
   ],
   "source": [
    "from german_credit_SS import SS, load_dataset as ld"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dhasade/.local/lib/python3.8/site-packages/sklearn/datasets/_openml.py:1022: FutureWarning: The default value of `parser` will change from `'liac-arff'` to `'auto'` in 1.4. You can set `parser='auto'` to silence this warning. Therefore, an `ImportError` will be raised from 1.4 if the dataset is dense and pandas is not installed. Note that the pandas parser may return different data types. See the Notes Section in fetch_openml's API doc for details.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "X, y = ld()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# update index of X to just integers\n",
    "X = X.reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=1000, step=1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "attribute = 'age'\n",
    "X_1 = X[X[attribute] == 1]\n",
    "y_1 = y[X[attribute] == 1]\n",
    "\n",
    "X_0 = X[X[attribute] == 0]\n",
    "y_0 = y[X[attribute] == 0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_1 = X_1.sample(n=10, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiIndex([('female', 'aged', 'yes'),\n",
       "            (  'male', 'aged', 'yes'),\n",
       "            ('female', 'aged', 'yes'),\n",
       "            (  'male', 'aged', 'yes'),\n",
       "            (  'male', 'aged', 'yes'),\n",
       "            (  'male', 'aged', 'yes'),\n",
       "            ('female', 'aged', 'yes'),\n",
       "            (  'male', 'aged', 'yes'),\n",
       "            (  'male', 'aged', 'yes'),\n",
       "            (  'male', 'aged', 'yes')],\n",
       "           names=['sex', 'age', 'foreign_worker'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset_1.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/dhasade/audits/ml-audits/demographic_parity_german_credit.ipynb Cell 15\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Blabosgodzilla.iccluster.epfl.ch/home/dhasade/audits/ml-audits/demographic_parity_german_credit.ipynb#X42sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m subset, subset_y \u001b[39m=\u001b[39m SS(X, y, \u001b[39m100\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mage\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m~/audits/ml-audits/german_credit_SS.py:54\u001b[0m, in \u001b[0;36mSS\u001b[0;34m(X, y, n, attribute, random_seed)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[39m# sample sub_n from each subspace\u001b[39;00m\n\u001b[1;32m     53\u001b[0m subset_1 \u001b[39m=\u001b[39m X_1\u001b[39m.\u001b[39msample(n\u001b[39m=\u001b[39msub_n, random_state\u001b[39m=\u001b[39mrandom_state)\n\u001b[0;32m---> 54\u001b[0m subset_y_1 \u001b[39m=\u001b[39m y_1[subset_1\u001b[39m.\u001b[39;49mindex]\n\u001b[1;32m     55\u001b[0m subset_0 \u001b[39m=\u001b[39m X_0\u001b[39m.\u001b[39msample(n\u001b[39m=\u001b[39msub_n, random_state\u001b[39m=\u001b[39mrandom_state)\n\u001b[1;32m     56\u001b[0m subset_y_0 \u001b[39m=\u001b[39m y_0[subset_0\u001b[39m.\u001b[39mindex]\n",
      "\u001b[0;31mIndexError\u001b[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
     ]
    }
   ],
   "source": [
    "subset, subset_y = SS(X, y, 100, 'age')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(age = 1): 0.81\n",
      "P(age = 0): 0.18999999999999995\n",
      "P(sex = 1): 0.69\n",
      "P(sex = 0): 0.31000000000000005\n"
     ]
    }
   ],
   "source": [
    "# Calculate the probabilities\n",
    "prob_age_1 = X['age'].mean()  # P(age = 1)\n",
    "prob_age_0 = 1 - prob_age_1   # P(age = 0)\n",
    "\n",
    "prob_sex_1 = X['sex'].mean()  # P(sex = 1)\n",
    "prob_sex_0 = 1 - prob_sex_1   # P(sex = 0)\n",
    "\n",
    "print(\"P(age = 1):\", prob_age_1)\n",
    "print(\"P(age = 0):\", prob_age_0)\n",
    "print(\"P(sex = 1):\", prob_sex_1)\n",
    "print(\"P(sex = 0):\", prob_sex_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(y=1|age=0): 0.5789473684210527\n",
      "P(y=1|age=1): 0.7283950617283951\n",
      "P(y=1|sex=0): 0.6483870967741936\n",
      "P(y=1|sex=1): 0.7231884057971014\n"
     ]
    }
   ],
   "source": [
    "# Calculate the conditional probabilities\n",
    "prob_y_given_age_0 = y[X['age'] == 0].mean()  # P(y=1|age=0)\n",
    "prob_y_given_age_1 = y[X['age'] == 1].mean()  # P(y=1|age=1)\n",
    "\n",
    "prob_y_given_sex_0 = y[X['sex'] == 0].mean()  # P(y=1|sex=0)\n",
    "prob_y_given_sex_1 = y[X['sex'] == 1].mean()  # P(y=1|sex=1)\n",
    "\n",
    "print(\"P(y=1|age=0):\", prob_y_given_age_0)\n",
    "print(\"P(y=1|age=1):\", prob_y_given_age_1)\n",
    "print(\"P(y=1|sex=0):\", prob_y_given_sex_0)\n",
    "print(\"P(y=1|sex=1):\", prob_y_given_sex_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P(y=1|sex=1, age=1): 0.7388429752066116\n",
      "P(y=1|sex=1, age=0): 0.611764705882353\n",
      "P(y=1|sex=0, age=1): 0.697560975609756\n",
      "P(y=1|sex=0, age=0): 0.5523809523809524\n"
     ]
    }
   ],
   "source": [
    "# Calculate the joint probabilities\n",
    "prob_y_given_sex_1_and_age_1 = y[(X['sex'] == 1) & (X['age'] == 1)].mean()  # P(y=1|sex=1, age=1)\n",
    "prob_y_given_sex_1_and_age_0 = y[(X['sex'] == 1) & (X['age'] == 0)].mean()  # P(y=1|sex=1, age=0)\n",
    "prob_y_given_sex_0_and_age_1 = y[(X['sex'] == 0) & (X['age'] == 1)].mean()  # P(y=1|sex=0, age=1)\n",
    "prob_y_given_sex_0_and_age_0 = y[(X['sex'] == 0) & (X['age'] == 0)].mean()  # P(y=1|sex=0, age=0)\n",
    "\n",
    "print(\"P(y=1|sex=1, age=1):\", prob_y_given_sex_1_and_age_1)\n",
    "print(\"P(y=1|sex=1, age=0):\", prob_y_given_sex_1_and_age_0)\n",
    "print(\"P(y=1|sex=0, age=1):\", prob_y_given_sex_0_and_age_1)\n",
    "print(\"P(y=1|sex=0, age=0):\", prob_y_given_sex_0_and_age_0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def demographic_parity(samples, y, attribute):\n",
    "    # Calculate demographic parity for 'attribute'\n",
    "    prob_y_given_attribute_1 = y[samples[attribute] == 1].mean()  # P(y=1|attribute=1)\n",
    "    prob_y_given_attribute_0 = y[samples[attribute] == 0].mean()  # P(y=1|attribute=0)\n",
    "\n",
    "    demographic_parity_attribute = abs(prob_y_given_attribute_1 - prob_y_given_attribute_0)\n",
    "\n",
    "    return demographic_parity_attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Demographic Parity for 'sex': 0.07480130902290782\n",
      "Demographic Parity for 'age': 0.14944769330734242\n"
     ]
    }
   ],
   "source": [
    "# Demographic parity in the original dataset\n",
    "demographic_parity_age = demographic_parity(X, y, 'age')\n",
    "demographic_parity_sex = demographic_parity(X, y, 'sex')\n",
    "\n",
    "print(\"Demographic Parity for 'sex':\", demographic_parity_sex)\n",
    "print(\"Demographic Parity for 'age':\", demographic_parity_age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split X and y into train, test and audit splits of 45%, 5% and 50% respectively\n",
    "random_seed = 40\n",
    "X_train, X_audit, y_train, y_audit = train_test_split(X, y, test_size=0.5, random_state=random_seed)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train, test_size=0.1, random_state=random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define models to test\n",
    "def get_models():\n",
    "    models, names = list(), list()\n",
    "    # LR\n",
    "    models.append(LogisticRegression(solver='liblinear'))\n",
    "    names.append('LR')\n",
    "    # LDA\n",
    "    models.append(LinearDiscriminantAnalysis())\n",
    "    names.append('LDA')\n",
    "    # NB\n",
    "    models.append(GaussianNB())\n",
    "    names.append('NB')\n",
    "    # GPC\n",
    "    models.append(GaussianProcessClassifier())\n",
    "    names.append('GPC')\n",
    "    # SVM\n",
    "    models.append(SVC(gamma='scale'))\n",
    "    names.append('SVM')\n",
    "    return models, names\n",
    "\n",
    "models, names = get_models()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the preprocessing\n",
    "ct = ColumnTransformer([('c',OneHotEncoder(),cat_ix), ('n',MinMaxScaler(),num_ix)])\n",
    "X_train = ct.fit_transform(X_train)\n",
    "X_test = ct.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LR Accuracy: 0.82\n",
      "LDA Accuracy: 0.78\n",
      "NB Accuracy: 0.5\n",
      "GPC Accuracy: 0.72\n",
      "SVM Accuracy: 0.78\n",
      "Best model: LR with accuracy: 0.82\n"
     ]
    }
   ],
   "source": [
    "models, names = get_models()\n",
    "best_acc = 0.0; best_model = None; best_model_name = None\n",
    "for i in range(len(models)):\n",
    "\n",
    "    model = models[i]\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # evaluate the model\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(f\"{names[i]} Accuracy: {accuracy}\")\n",
    "\n",
    "    if accuracy > best_acc:\n",
    "        best_acc = accuracy\n",
    "        best_model = model\n",
    "        best_model_name = names[i]\n",
    "\n",
    "print(f\"Best model: {best_model_name} with accuracy: {best_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Demographic Parity for 'age': 0.22612085769980506\n",
      "Demographic Parity for 'sex': 0.15521271622253385\n"
     ]
    }
   ],
   "source": [
    "# Calculate the ground truth demographic parity of the best model\n",
    "# This should be done on all data (train + test+ audit)\n",
    "X_temp = ct.transform(X)\n",
    "y_pred = best_model.predict(X_temp)\n",
    "\n",
    "# Calculate demographic parity for 'age'\n",
    "prob_y_given_age_1 = y_pred[X['age'] == 1].mean()  # P(y=1|age=1)\n",
    "prob_y_given_age_0 = y_pred[X['age'] == 0].mean()  # P(y=1|age=0)\n",
    "\n",
    "demographic_parity_age_of_model = abs(prob_y_given_age_1 - prob_y_given_age_0)\n",
    "print(\"Demographic Parity for 'age':\", demographic_parity_age_of_model)\n",
    "\n",
    "# Calculate demographic parity for 'sex'\n",
    "prob_y_given_sex_1 = y_pred[X['sex'] == 1].mean()  # P(y=1|sex=1)\n",
    "prob_y_given_sex_0 = y_pred[X['sex'] == 0].mean()  # P(y=1|sex=0)\n",
    "\n",
    "demographic_parity_sex_of_model = abs(prob_y_given_sex_1 - prob_y_given_sex_0)\n",
    "print(\"Demographic Parity for 'sex':\", demographic_parity_sex_of_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_DP(samples, y, attribute, groud_truth_dp):\n",
    "    # Calculate the error in demographic parity for 'attribute'\n",
    "    return np.abs(groud_truth_dp - demographic_parity(samples, y, attribute))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ct_new = ColumnTransformer([('c',OneHotEncoder(),cat_ix), ('n',MinMaxScaler(),num_ix)])\n",
    "ct_new.fit_transform(X_audit)\n",
    "\n",
    "def BlackBox(samples):\n",
    "    '''\n",
    "    The black-box algorithm to audit\n",
    "    samples : pandas.DataFrame\n",
    "        The dataset.\n",
    "    '''\n",
    "    # transform using the same ColumnTransformer object used for the training data\n",
    "    transformed_samples = ct_new.transform(samples)\n",
    "    # predict\n",
    "    yhat = best_model.predict(transformed_samples)\n",
    "\n",
    "    # return yhat along with samples\n",
    "    return samples, yhat\n",
    "\n",
    "def RS(samples, n, attribute):\n",
    "    '''\n",
    "    Random Sampling.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    samples : pandas.DataFrame\n",
    "        The dataset.\n",
    "    n : int\n",
    "        The number of samples to be generated.\n",
    "    attribute : str\n",
    "        The attribute to be sampled.\n",
    "\n",
    "    Attribute is not used in the method.\n",
    "    '''\n",
    "\n",
    "    subset = samples.sample(n=n, random_state=42)\n",
    "    \n",
    "    return BlackBox(subset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error in demographic parity for 'age': 0.35324422166527425\n",
      "Error in demographic parity for 'sex': 0.1434885824787649\n"
     ]
    }
   ],
   "source": [
    "samples, yhat = RS(X_audit, 25, 'age')\n",
    "\n",
    "# calculate the error in demographic parity for 'age'\n",
    "error_age = error_DP(samples, yhat, 'age')\n",
    "print(\"Error in demographic parity for 'age':\", error_age)\n",
    "\n",
    "samples, yhat = RS(X_audit, 25, 'sex')\n",
    "\n",
    "# calculate the error in demographic parity for 'sex'\n",
    "error_sex = error_DP(samples, yhat, 'sex')\n",
    "print(\"Error in demographic parity for 'sex':\", error_sex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "audits",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
