{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from folktables import ACSDataSource, ACSPublicCoverage\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "protected_attributes = [\n",
    "    'SEX',\n",
    "    'DIS',\n",
    "    'NATIVITY',\n",
    "    'DEAR',\n",
    "    'DEYE',\n",
    "    'MIG',\n",
    "    'MIL',\n",
    "    'AGEP',\n",
    "    'DREM',\n",
    "    'MAR',\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_source = ACSDataSource(survey_year='2018', horizon='5-Year', survey='person')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "acs_data = data_source.get_data(join_household=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/audits/lib/python3.8/site-packages/pandas/core/indexes/base.py:3653\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3652\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3653\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3654\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/anaconda3/envs/audits/lib/python3.8/site-packages/pandas/_libs/index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/audits/lib/python3.8/site-packages/pandas/_libs/index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 0",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/home/dhasade/audits/folk_draft.ipynb Cell 4\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Blabostrex109.iccluster.epfl.ch/home/dhasade/audits/folk_draft.ipynb#X42sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mlen\u001b[39m(acs_data[\u001b[39m0\u001b[39;49m])\n",
      "File \u001b[0;32m~/anaconda3/envs/audits/lib/python3.8/site-packages/pandas/core/frame.py:3761\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3759\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   3760\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3761\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[1;32m   3762\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3763\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/anaconda3/envs/audits/lib/python3.8/site-packages/pandas/core/indexes/base.py:3655\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3653\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3654\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m-> 3655\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3656\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3657\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3658\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3659\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3660\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 0"
     ]
    }
   ],
   "source": [
    "len(acs_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'AGEP'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/anaconda3/envs/audits/lib/python3.8/site-packages/pandas/core/indexes/base.py:3653\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3652\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 3653\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_engine\u001b[39m.\u001b[39;49mget_loc(casted_key)\n\u001b[1;32m   3654\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n",
      "File \u001b[0;32m~/anaconda3/envs/audits/lib/python3.8/site-packages/pandas/_libs/index.pyx:147\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/audits/lib/python3.8/site-packages/pandas/_libs/index.pyx:176\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'AGEP'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/home/dhasade/audits/folk_draft.ipynb Cell 4\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Blabostrex109.iccluster.epfl.ch/home/dhasade/audits/folk_draft.ipynb#W3sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m features, label, group \u001b[39m=\u001b[39m ACSPublicCoverage\u001b[39m.\u001b[39;49mdf_to_pandas(acs_data)\n",
      "File \u001b[0;32m~/audits/folktables/folktables/folktables.py:116\u001b[0m, in \u001b[0;36mBasicProblem.df_to_pandas\u001b[0;34m(self, df, categories, dummies)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdf_to_pandas\u001b[39m(\u001b[39mself\u001b[39m, df, categories\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, dummies\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m    104\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Filters and processes a DataFrame (received from ```ACSDataSource''').\u001b[39;00m\n\u001b[1;32m    105\u001b[0m \u001b[39m    \u001b[39;00m\n\u001b[1;32m    106\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39m    Returns:\u001b[39;00m\n\u001b[1;32m    114\u001b[0m \u001b[39m        pandas.DataFrame.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 116\u001b[0m     df \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_preprocess(df)\n\u001b[1;32m    118\u001b[0m     variables \u001b[39m=\u001b[39m df[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeatures]\n\u001b[1;32m    120\u001b[0m     \u001b[39mif\u001b[39;00m categories:\n",
      "File \u001b[0;32m~/audits/folktables/folktables/acs.py:170\u001b[0m, in \u001b[0;36mpublic_coverage_filter\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    167\u001b[0m \u001b[39mFilters for the public health insurance prediction task; focus on low income Americans, and those not eligible for Medicare\u001b[39;00m\n\u001b[1;32m    168\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    169\u001b[0m df \u001b[39m=\u001b[39m data\n\u001b[0;32m--> 170\u001b[0m df \u001b[39m=\u001b[39m df[df[\u001b[39m'\u001b[39;49m\u001b[39mAGEP\u001b[39;49m\u001b[39m'\u001b[39;49m] \u001b[39m<\u001b[39m \u001b[39m65\u001b[39m]\n\u001b[1;32m    171\u001b[0m df \u001b[39m=\u001b[39m df[df[\u001b[39m'\u001b[39m\u001b[39mPINCP\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m30000\u001b[39m]\n\u001b[1;32m    172\u001b[0m \u001b[39mreturn\u001b[39;00m df\n",
      "File \u001b[0;32m~/anaconda3/envs/audits/lib/python3.8/site-packages/pandas/core/frame.py:3761\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3759\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcolumns\u001b[39m.\u001b[39mnlevels \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m   3760\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 3761\u001b[0m indexer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcolumns\u001b[39m.\u001b[39;49mget_loc(key)\n\u001b[1;32m   3762\u001b[0m \u001b[39mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   3763\u001b[0m     indexer \u001b[39m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/anaconda3/envs/audits/lib/python3.8/site-packages/pandas/core/indexes/base.py:3655\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3653\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine\u001b[39m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3654\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m-> 3655\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key) \u001b[39mfrom\u001b[39;00m \u001b[39merr\u001b[39;00m\n\u001b[1;32m   3656\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mTypeError\u001b[39;00m:\n\u001b[1;32m   3657\u001b[0m     \u001b[39m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3658\u001b[0m     \u001b[39m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3659\u001b[0m     \u001b[39m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3660\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'AGEP'"
     ]
    }
   ],
   "source": [
    "features, label, group = ACSPublicCoverage.df_to_pandas(acs_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the loaded data into a csv file\n",
    "# features.to_csv('./my_data/features.csv', index=False)\n",
    "# label.to_csv('./my_data/label.csv', index=False)\n",
    "# group.to_csv('./my_data/group.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the pandas data frames\n",
    "features = pd.read_csv('./my_data/features.csv')\n",
    "label = pd.read_csv('./my_data/label.csv')\n",
    "group = pd.read_csv('./my_data/group.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load as numpy\n",
    "features_np, label_np, group_np = ACSPublicCoverage.df_to_numpy(acs_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the numpy files\n",
    "np.save('./my_data/features.npy', features_np)\n",
    "np.save('./my_data/label.npy', label_np)\n",
    "np.save('./my_data/group.npy', group_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Protected attribute: SEX\n",
      "SEX = 1: 0.43 and SEX = 2: 0.57\n",
      "Protected attribute: DIS\n",
      "DIS = 1: 0.15 and DIS = 2: 0.85\n",
      "Protected attribute: NATIVITY\n",
      "NATIVITY = 1: 0.85 and NATIVITY = 2: 0.15\n",
      "Protected attribute: DEAR\n",
      "DEAR = 1: 0.02 and DEAR = 2: 0.98\n",
      "Protected attribute: DEYE\n",
      "DEYE = 1: 0.03 and DEYE = 2: 0.97\n"
     ]
    }
   ],
   "source": [
    "for protect_attr in protected_attributes[:5]:\n",
    "    print(f'Protected attribute: {protect_attr}')\n",
    "    # Calculate prob_attr = P(protect_attr = 1) when attr can take 1 or 2\n",
    "    prob_attr_1 = np.mean(features[protect_attr] == 1)\n",
    "    prob_attr_0 = np.mean(features[protect_attr] == 2)\n",
    "    print(f'{protect_attr} = 1: {prob_attr_1:.2f} and {protect_attr} = 2: {prob_attr_0:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIL = 1 or 4: 0.90 and MIL = 0, 2 or 3: 0.10\n"
     ]
    }
   ],
   "source": [
    "# Calculate prob_attr = P(protect_attr = 1 or 4) when attr can take 0, 1, 2, 3, 4\n",
    "protect_attr = 'MIL'\n",
    "prob_attr_1 = np.mean((features[protect_attr] == 1) | (features[protect_attr] == 4))\n",
    "prob_attr_0 = np.mean((features[protect_attr] == 0) | (features[protect_attr] == 2) | (features[protect_attr] == 3))\n",
    "print(f'{protect_attr} = 1 or 4: {prob_attr_1:.2f} and {protect_attr} = 0, 2 or 3: {prob_attr_0:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MIG = 1: 0.82 and MIG = 0, 2 or 3: 0.18\n"
     ]
    }
   ],
   "source": [
    "# Calculate prob_attr = P(protect_attr = 1) when attr can take 0, 1, 2, 3\n",
    "protect_attr = 'MIG'\n",
    "prob_attr_1 = np.mean(features[protect_attr] == 1)\n",
    "prob_attr_0 = np.mean(features[protect_attr].isin([0, 2, 3]))\n",
    "print(f'{protect_attr} = 1: {prob_attr_1:.2f} and {protect_attr} = 0, 2 or 3: {prob_attr_0:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AGEP > 25: 0.66 and AGEP <= 25: 0.34\n"
     ]
    }
   ],
   "source": [
    "# Calculate prob_attr = P(protect_attr = 1) by thresholding at age 25\n",
    "protect_attr = 'AGEP'\n",
    "prob_attr_1 = np.mean(features[protect_attr] > 25)\n",
    "prob_attr_0 = np.mean(features[protect_attr] <= 25)\n",
    "print(f'{protect_attr} > 25: {prob_attr_1:.2f} and {protect_attr} <= 25: {prob_attr_0:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAR = 1: 0.37 and MAR = 0, 2, 3 or 4: 0.63\n"
     ]
    }
   ],
   "source": [
    "# Calculate prob_attr = P(protect_attr = 1) when attr can take 1, 2, 3, 4, 5\n",
    "protect_attr = 'MAR'\n",
    "prob_attr_1 = np.mean(features[protect_attr] == 1)\n",
    "prob_attr_0 = np.mean(features[protect_attr].isin([2, 3, 4, 5]))\n",
    "print(f'{protect_attr} = 1: {prob_attr_1:.2f} and {protect_attr} = 0, 2, 3 or 4: {prob_attr_0:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DREM = 1: 0.08 and DREM = 0, 2: 0.92\n"
     ]
    }
   ],
   "source": [
    "# Calculate prob_attr = P(protect_attr = 1) when attr can take 0, 1, 2\n",
    "protect_attr = 'DREM'\n",
    "prob_attr_1 = np.mean(features[protect_attr] == 1)\n",
    "prob_attr_0 = np.mean(features[protect_attr].isin([0,2]))\n",
    "print(f'{protect_attr} = 1: {prob_attr_1:.2f} and {protect_attr} = 0, 2: {prob_attr_0:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_pipeline(StandardScaler(), GradientBoostingClassifier(loss='exponential', n_estimators=5, max_depth=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, group_train, group_test = train_test_split(\n",
    "    features, label, group, test_size=0.2, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/dhasade/anaconda3/envs/audits/lib/python3.8/site-packages/sklearn/ensemble/_gb.py:424: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;standardscaler&#x27;, StandardScaler()),\n",
       "                (&#x27;gradientboostingclassifier&#x27;,\n",
       "                 GradientBoostingClassifier(loss=&#x27;exponential&#x27;, max_depth=5,\n",
       "                                            n_estimators=5))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;standardscaler&#x27;, StandardScaler()),\n",
       "                (&#x27;gradientboostingclassifier&#x27;,\n",
       "                 GradientBoostingClassifier(loss=&#x27;exponential&#x27;, max_depth=5,\n",
       "                                            n_estimators=5))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GradientBoostingClassifier</label><div class=\"sk-toggleable__content\"><pre>GradientBoostingClassifier(loss=&#x27;exponential&#x27;, max_depth=5, n_estimators=5)</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('standardscaler', StandardScaler()),\n",
       "                ('gradientboostingclassifier',\n",
       "                 GradientBoostingClassifier(loss='exponential', max_depth=5,\n",
       "                                            n_estimators=5))])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset():\n",
    "    # load the pandas data frames\n",
    "    features = pd.read_csv('./my_data/features.csv')\n",
    "    label = pd.read_csv('./my_data/label.csv')\n",
    "    return features, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7127843605199977\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def demographic_parity(samples, y, attribute):\n",
    "    # Calculate demographic parity for 'attribute'\n",
    "\n",
    "    binary_attributes = ['SEX','DIS','NATIVITY','DEAR','DEYE']\n",
    "\n",
    "    n = len(samples)\n",
    "\n",
    "    if attribute in binary_attributes:\n",
    "        # if the auditor doesn't test all subpopulations, we set that the demographic parity is null\n",
    "        if not (0 < y[samples[attribute] == 1].sum().item() < n) or not (0 < y[samples[attribute] == 2].sum().item() < n):\n",
    "            return 0\n",
    "\n",
    "        prob_y_given_attribute_1 = y[samples[attribute] == 1].mean().item()  # P(y=1|attribute=1)\n",
    "        prob_y_given_attribute_0 = y[samples[attribute] == 2].mean().item()  # P(y=1|attribute=0)\n",
    "\n",
    "    elif attribute == 'MIL':\n",
    "        prob_y_given_attribute_1 = y[samples[attribute].isin([1,4])].mean().item()\n",
    "        prob_y_given_attribute_0 = y[samples[attribute].isin([0,2,3])].mean().item()\n",
    "\n",
    "    elif attribute == 'MIG':\n",
    "        prob_y_given_attribute_1 = y[samples[attribute] == 1].mean().item()\n",
    "        prob_y_given_attribute_0 = y[samples[attribute].isin([0,2,3])].mean().item()\n",
    "    \n",
    "    elif attribute == 'AGEP':\n",
    "        prob_y_given_attribute_1 = y[samples[attribute] > 25].mean().item()\n",
    "        prob_y_given_attribute_0 = y[samples[attribute] <= 25].mean().item()\n",
    "    \n",
    "    elif attribute == 'MAR':\n",
    "        prob_y_given_attribute_1 = y[samples[attribute] == 1].mean().item()\n",
    "        prob_y_given_attribute_0 = y[samples[attribute].isin([2,3,4,5])].mean().item()\n",
    "\n",
    "    elif attribute == 'DREM':\n",
    "        prob_y_given_attribute_1 = y[samples[attribute] == 1].mean().item()\n",
    "        prob_y_given_attribute_0 = y[samples[attribute].isin([0,2])].mean().item()\n",
    "\n",
    "    else:\n",
    "        raise ValueError('Attribute not supported')\n",
    "\n",
    "    demographic_parity_attribute = abs(prob_y_given_attribute_1 - prob_y_given_attribute_0)\n",
    "    return demographic_parity_attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "protected_attributes = [\n",
    "    'SEX',\n",
    "    'DIS',\n",
    "    'NATIVITY',\n",
    "    'DEAR',\n",
    "    'DEYE'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Demographic parity for SEX: 0.03\n",
      "Demographic parity for DIS: 0.41\n",
      "Demographic parity for NATIVITY: 0.05\n",
      "Demographic parity for DEAR: 0.27\n",
      "Demographic parity for DEYE: 0.31\n"
     ]
    }
   ],
   "source": [
    "for attr in protected_attributes:\n",
    "    dp = demographic_parity(features, label, attr)\n",
    "    print(f'Demographic parity for {attr}: {dp:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4449089426372358"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demographic_parity(features, label, 'DREM')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7127970367941534"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1.0 - label.mean().item()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code for unbiasing DP estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from folk_tables import load_dataset, protected_attributes, class_mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform X based on class_mappings\n",
    "X_transformed = X.copy()\n",
    "for attr in protected_attributes:\n",
    "    if attr == 'AGEP':\n",
    "        X_transformed[attr] = X_transformed[attr].apply(lambda x: 1 if x > 25 else 0)\n",
    "    else:\n",
    "        class_mapping = class_mappings(attr)\n",
    "        C1 = class_mapping[1] # list of values that are mapped to 1\n",
    "        C0 = class_mapping[0] # list of values that are mapped to 0\n",
    "        X_transformed[attr] = X_transformed[attr].apply(lambda x: 1 if x in C1 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on k=2\n",
      "Working on ['SEX', 'DIS']\n",
      "Working on ['SEX', 'NATIVITY']\n",
      "Working on ['SEX', 'DEAR']\n",
      "Working on ['SEX', 'DEYE']\n",
      "Working on ['SEX', 'MIG']\n",
      "Working on ['SEX', 'MIL']\n",
      "Working on ['SEX', 'AGEP']\n",
      "Working on ['SEX', 'DREM']\n",
      "Working on ['SEX', 'MAR']\n",
      "Working on ['DIS', 'NATIVITY']\n",
      "Working on ['DIS', 'DEAR']\n",
      "Working on ['DIS', 'DEYE']\n",
      "Working on ['DIS', 'MIG']\n",
      "Working on ['DIS', 'MIL']\n",
      "Working on ['DIS', 'AGEP']\n",
      "Working on ['DIS', 'DREM']\n",
      "Working on ['DIS', 'MAR']\n",
      "Working on ['NATIVITY', 'DEAR']\n",
      "Working on ['NATIVITY', 'DEYE']\n",
      "Working on ['NATIVITY', 'MIG']\n",
      "Working on ['NATIVITY', 'MIL']\n",
      "Working on ['NATIVITY', 'AGEP']\n",
      "Working on ['NATIVITY', 'DREM']\n",
      "Working on ['NATIVITY', 'MAR']\n",
      "Working on ['DEAR', 'DEYE']\n",
      "Working on ['DEAR', 'MIG']\n",
      "Working on ['DEAR', 'MIL']\n",
      "Working on ['DEAR', 'AGEP']\n",
      "Working on ['DEAR', 'DREM']\n",
      "Working on ['DEAR', 'MAR']\n",
      "Working on ['DEYE', 'MIG']\n",
      "Working on ['DEYE', 'MIL']\n",
      "Working on ['DEYE', 'AGEP']\n",
      "Working on ['DEYE', 'DREM']\n",
      "Working on ['DEYE', 'MAR']\n",
      "Working on ['MIG', 'MIL']\n",
      "Working on ['MIG', 'AGEP']\n",
      "Working on ['MIG', 'DREM']\n",
      "Working on ['MIG', 'MAR']\n",
      "Working on ['MIL', 'AGEP']\n",
      "Working on ['MIL', 'DREM']\n",
      "Working on ['MIL', 'MAR']\n",
      "Working on ['AGEP', 'DREM']\n",
      "Working on ['AGEP', 'MAR']\n",
      "Working on ['DREM', 'MAR']\n"
     ]
    }
   ],
   "source": [
    "all_probs = dict()\n",
    "n = 10\n",
    "\n",
    "for k in range(2,3):\n",
    "    print(f'Working on k={k}')\n",
    "    all_probs[k] = dict()\n",
    "\n",
    "    agent_combinations_list = list(combinations(range(n), k))\n",
    "\n",
    "    for agent_combination in agent_combinations_list:\n",
    "        agent_comb_str = ''.join([str(elem) for elem in agent_combination])\n",
    "        \n",
    "        all_probs[k][agent_comb_str] = dict()\n",
    "\n",
    "        total_strings = 2**(k)\n",
    "        binary_strings = [format(i, f'0{k}b') for i in range(total_strings)]\n",
    "\n",
    "        attrs = [protected_attributes[i] for i in agent_combination]\n",
    "        print(f'Working on {attrs}')\n",
    "        for binary_string in binary_strings:\n",
    "            \n",
    "            pairs = [(attrs[i], int(binary_string[i])) for i in range(k)]\n",
    "\n",
    "            # Restore X_transformed that satisfies the binary string\n",
    "            X_temp = X_transformed\n",
    "            for attr, val in pairs:\n",
    "                X_temp = X_temp[X_temp[attr] == val]\n",
    "\n",
    "            all_probs[k][agent_comb_str][binary_string] = len(X_temp) / len(X_transformed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the matrix\n",
    "import pickle\n",
    "with open('./my_data/all_probs_2.pkl', 'wb') as f:\n",
    "    pickle.dump(all_probs, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00 0.02566184940079252\n",
      "01 0.12448811092246938\n",
      "10 0.1549682966383366\n",
      "11 0.6948817430384016\n"
     ]
    }
   ],
   "source": [
    "d = all_probs[2]['25']\n",
    "\n",
    "for k, v in d.items():\n",
    "    print(k, v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['01', '02', '03', '04', '05', '06', '07', '08', '09', '12', '13', '14', '15', '16', '17', '18', '19', '23', '24', '25', '26', '27', '28', '29', '34', '35', '36', '37', '38', '39', '45', '46', '47', '48', '49', '56', '57', '58', '59', '67', '68', '69', '78', '79', '89'])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_probs[2].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k=1: 10 2\n",
      "k=2: 45 4\n",
      "k=3: 120 8\n",
      "k=4: 210 16\n",
      "k=5: 252 32\n",
      "k=6: 210 64\n",
      "k=7: 120 128\n",
      "k=8: 45 256\n",
      "k=9: 10 512\n",
      "k=10: 1 1024\n",
      "1023\n"
     ]
    }
   ],
   "source": [
    "# print lengths\n",
    "for k in range(1, n+1):\n",
    "    # String with all zeros of length k\n",
    "    all_zeros = ''.join(['0' for _ in range(k)])\n",
    "    a_key = list(all_probs[k].keys())[0]\n",
    "    print(f'k={k}: {len(all_probs[k])} {len(all_probs[k][a_key])}')\n",
    "    \n",
    "print(sum([len(all_probs[k]) for k in range(1, n+1)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from  folk_tables import load_dataset, protected_attributes, class_mappings, CS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = load_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "attr = 'SEX'\n",
    "collaborators = [protected_attributes[i] for i in [2,3,4,5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All attributes: ['NATIVITY', 'DEAR', 'DEYE', 'MIG', 'SEX']\n",
      "Processing 00000 with len 5\n",
      "Len of subspace 0: 81547\n",
      "Processing 00001 with len 5\n",
      "Len of subspace 1: 66570\n",
      "Processing 00010 with len 5\n",
      "Len of subspace 2: 434697\n",
      "Processing 00011 with len 5\n",
      "Len of subspace 3: 279704\n",
      "Processing 00100 with len 5\n",
      "Len of subspace 4: 1094\n",
      "Processing 00101 with len 5\n",
      "Len of subspace 5: 988\n",
      "Processing 00110 with len 5\n",
      "Len of subspace 6: 7164\n",
      "Processing 00111 with len 5\n",
      "Len of subspace 7: 5054\n",
      "Processing 01000 with len 5\n",
      "Len of subspace 8: 548\n",
      "Processing 01001 with len 5\n",
      "Len of subspace 9: 663\n",
      "Processing 01010 with len 5\n",
      "Len of subspace 10: 3882\n",
      "Processing 01011 with len 5\n",
      "Len of subspace 11: 3534\n",
      "Processing 01100 with len 5\n",
      "Len of subspace 12: 170\n",
      "Processing 01101 with len 5\n",
      "Len of subspace 13: 250\n",
      "Processing 01110 with len 5\n",
      "Len of subspace 14: 1228\n",
      "Processing 01111 with len 5\n",
      "Len of subspace 15: 1279\n",
      "Processing 10000 with len 5\n",
      "Len of subspace 16: 454518\n",
      "Processing 10001 with len 5\n",
      "Len of subspace 17: 420430\n",
      "Processing 10010 with len 5\n",
      "Len of subspace 18: 2248078\n",
      "Processing 10011 with len 5\n",
      "Len of subspace 19: 1663333\n",
      "Processing 10100 with len 5\n",
      "Len of subspace 20: 10265\n",
      "Processing 10101 with len 5\n",
      "Len of subspace 21: 10823\n",
      "Processing 10110 with len 5\n",
      "Len of subspace 22: 52512\n",
      "Processing 10111 with len 5\n",
      "Len of subspace 23: 42446\n",
      "Processing 11000 with len 5\n",
      "Len of subspace 24: 5931\n",
      "Processing 11001 with len 5\n",
      "Len of subspace 25: 9560\n",
      "Processing 11010 with len 5\n",
      "Len of subspace 26: 35587\n",
      "Processing 11011 with len 5\n",
      "Len of subspace 27: 45356\n",
      "Processing 11100 with len 5\n",
      "Len of subspace 28: 2144\n",
      "Processing 11101 with len 5\n",
      "Len of subspace 29: 3209\n",
      "Processing 11110 with len 5\n",
      "Len of subspace 30: 10790\n",
      "Processing 11111 with len 5\n",
      "Len of subspace 31: 13211\n"
     ]
    }
   ],
   "source": [
    "subset, subset_y = CS(X, y, 100, attr, collaborators=collaborators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.5"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset['NATIVITY'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print the heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_p = '/home/dhasade/audits/ml-audits/results/new_matrices/gains_CS_seed5_budget500_repeat1.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_matrix = pickle.load(open('/home/dhasade/audits/ml-audits/results/matrices/errors_CS_seed5_budget100_repeat1.pkl', 'rb'))\n",
    "gain_matrix = pickle.load(open(g_p, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.039 0.025 0.013 0.012 0.001 \n",
      "0.005 0.001 0.054 0.026 0.249 \n",
      "0.063 0.067 0.054 0.120 0.052 \n",
      "0.033 0.147 0.158 0.032 0.170 \n",
      "0.275 0.295 0.141 0.065 0.077 \n"
     ]
    }
   ],
   "source": [
    "# Nicely print the error matrix\n",
    "n = 5\n",
    "for i in range(n):\n",
    "    for j in range(n):\n",
    "        print(f'{error_matrix[i][j]:.3f}', end=' ')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.000 0.829 0.618 5.427 1.544 \n",
      "0.902 1.000 1.976 1.431 1.000 \n",
      "7.164 2.419 1.000 4.708 1.817 \n",
      "0.535 0.558 0.728 1.000 0.669 \n",
      "0.257 0.380 0.159 0.089 1.000 \n"
     ]
    }
   ],
   "source": [
    "# Nicely print the gain matrix\n",
    "n = 5\n",
    "for i in range(n):\n",
    "    for j in range(n):\n",
    "        print(f'{gain_matrix[i][j]:.3f}', end=' ')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Double checking dataframe calculations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tmp = X; y_tmp = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "attr = 'AGEP'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tmp = X_tmp[X[attr] > 50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tmp = y_tmp.loc[X_tmp.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PUBCOV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    PUBCOV\n",
       "0    False\n",
       "4    False\n",
       "5    False\n",
       "6    False\n",
       "17    True"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_tmp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGEP</th>\n",
       "      <th>SCHL</th>\n",
       "      <th>MAR</th>\n",
       "      <th>SEX</th>\n",
       "      <th>DIS</th>\n",
       "      <th>ESP</th>\n",
       "      <th>CIT</th>\n",
       "      <th>MIG</th>\n",
       "      <th>MIL</th>\n",
       "      <th>ANC</th>\n",
       "      <th>NATIVITY</th>\n",
       "      <th>DEAR</th>\n",
       "      <th>DEYE</th>\n",
       "      <th>DREM</th>\n",
       "      <th>PINCP</th>\n",
       "      <th>ESR</th>\n",
       "      <th>ST</th>\n",
       "      <th>FER</th>\n",
       "      <th>RAC1P</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>51.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>24000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>53.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>21000.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>51.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>28050.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>56.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24000.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    AGEP  SCHL  MAR  SEX  DIS  ESP  CIT  MIG  MIL  ANC  NATIVITY  DEAR  DEYE  \\\n",
       "0   59.0   1.0  1.0  2.0  1.0  0.0  1.0  1.0  4.0  1.0       1.0   2.0   2.0   \n",
       "4   51.0  16.0  1.0  1.0  2.0  0.0  1.0  1.0  3.0  1.0       1.0   2.0   2.0   \n",
       "5   53.0  16.0  1.0  2.0  2.0  0.0  1.0  1.0  4.0  2.0       1.0   2.0   2.0   \n",
       "6   51.0  16.0  1.0  1.0  2.0  0.0  1.0  1.0  4.0  4.0       1.0   2.0   2.0   \n",
       "17  56.0  12.0  1.0  1.0  1.0  0.0  1.0  1.0  4.0  1.0       1.0   2.0   2.0   \n",
       "\n",
       "    DREM    PINCP  ESR   ST  FER  RAC1P  \n",
       "0    2.0      0.0  6.0  1.0  0.0    1.0  \n",
       "4    2.0  24000.0  1.0  1.0  0.0    1.0  \n",
       "5    2.0  21000.0  1.0  1.0  0.0    1.0  \n",
       "6    2.0  28050.0  1.0  1.0  0.0    1.0  \n",
       "17   1.0  24000.0  6.0  1.0  0.0    2.0  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tmp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tmp = X_tmp[X_tmp[attr] > 55]\n",
    "y_tmp = y_tmp.loc[X_tmp.index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([      0,      17,      22,      35,      36,      37,      43,      52,\n",
       "            61,      63,\n",
       "       ...\n",
       "       5916510, 5916527, 5916528, 5916530, 5916532, 5916533, 5916537, 5916542,\n",
       "       5916548, 5916563],\n",
       "      dtype='int64', length=1039465)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tmp.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([      0,      17,      22,      35,      36,      37,      43,      52,\n",
       "            61,      63,\n",
       "       ...\n",
       "       5916510, 5916527, 5916528, 5916530, 5916532, 5916533, 5916537, 5916542,\n",
       "       5916548, 5916563],\n",
       "      dtype='int64', length=1039465)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_tmp.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_attrs=3\n",
    "n_subspaces = 2**n_attrs\n",
    "binary_strings = [format(i, f'0{n_attrs}b') for i in range(n_subspaces)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['000', '001', '010', '011', '100', '101', '110', '111']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "binary_strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "audits",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
